package services

import (
	"encoding/json"
	"fmt"
	"regexp"
	"strings"
	"time"

	"github.com/autolog/backend/internal/logger"
	"github.com/autolog/backend/internal/models"
	"gorm.io/gorm"
)

// DynamicParserService uses LLM to generate regex patterns for log parsing
type DynamicParserService struct {
	llmService *LLMService
	db         *gorm.DB
}

// GeneratedPattern represents a regex pattern generated by LLM
type GeneratedPattern struct {
	Name        string            `json:"name"`
	Description string            `json:"description"`
	Regex       string            `json:"regex"`
	Fields      []string          `json:"fields"`
	Confidence  float64           `json:"confidence"`
	Examples    []string          `json:"examples"`
	Metadata    map[string]string `json:"metadata"`
}

// PatternAnalysisRequest represents a request to analyze log patterns
type PatternAnalysisRequest struct {
	LogLines    []string `json:"logLines"`
	SampleSize  int      `json:"sampleSize"`
	MaxPatterns int      `json:"maxPatterns"`
}

// PatternAnalysisResponse represents the LLM response for pattern analysis
type PatternAnalysisResponse struct {
	Patterns []GeneratedPattern `json:"patterns"`
	Summary  string             `json:"summary"`
	Quality  string             `json:"quality"`
}

func NewDynamicParserService(llmService *LLMService, db *gorm.DB) *DynamicParserService {
	return &DynamicParserService{
		llmService: llmService,
		db:         db,
	}
}

// AnalyzeLogPatterns uses LLM to analyze log lines and generate regex patterns
func (dps *DynamicParserService) AnalyzeLogPatterns(logLines []string, sampleSize int) ([]GeneratedPattern, error) {
	logEntry := logger.WithContext(map[string]interface{}{
		"component":   "dynamic_parser",
		"total_lines": len(logLines),
		"sample_size": sampleSize,
		"operation":   "analyze_patterns",
	})

	logEntry.Info("Starting dynamic pattern analysis")

	// Take a sample of log lines for analysis
	sampleLines := dps.getSampleLines(logLines, sampleSize)

	// Create the analysis request
	request := PatternAnalysisRequest{
		LogLines:    sampleLines,
		SampleSize:  len(sampleLines),
		MaxPatterns: 5, // Generate up to 5 patterns
	}

	// Generate prompt for LLM
	prompt := dps.createPatternAnalysisPrompt(request)

	// Call LLM to generate patterns
	response, err := dps.llmService.callLLMWithContext(prompt, nil, nil, "pattern_generation")
	if err != nil {
		logEntry.Error("LLM pattern generation failed", map[string]interface{}{
			"error": err.Error(),
		})
		return nil, fmt.Errorf("LLM pattern generation failed: %w", err)
	}

	// Parse LLM response
	patterns, err := dps.parsePatternAnalysisResponse(response)
	if err != nil {
		logEntry.Error("Failed to parse LLM pattern response", map[string]interface{}{
			"error": err.Error(),
		})
		return nil, fmt.Errorf("failed to parse LLM pattern response: %w", err)
	}

	// Validate and test patterns
	validatedPatterns := dps.validatePatterns(patterns, sampleLines)

	logEntry.Info("Dynamic pattern analysis completed", map[string]interface{}{
		"patterns_generated": len(patterns),
		"patterns_valid":     len(validatedPatterns),
	})

	return validatedPatterns, nil
}

// ParseLogsWithDynamicPatterns uses generated patterns to parse log lines
func (dps *DynamicParserService) ParseLogsWithDynamicPatterns(logLines []string, patterns []GeneratedPattern) ([]models.LogEntry, error) {
	logEntry := logger.WithContext(map[string]interface{}{
		"component":      "dynamic_parser",
		"total_lines":    len(logLines),
		"patterns_count": len(patterns),
		"operation":      "parse_with_patterns",
	})

	logEntry.Info("Starting dynamic log parsing")

	var entries []models.LogEntry
	var unparsedLines []string

	for i, line := range logLines {
		parsed := false

		// Try each pattern until one matches
		for _, pattern := range patterns {
			if entry := dps.parseLineWithPattern(line, pattern, uint(i+1)); entry != nil {
				entries = append(entries, *entry)
				parsed = true
				break
			}
		}

		if !parsed {
			unparsedLines = append(unparsedLines, line)
		}
	}

	// If we have unparsed lines, try to generate additional patterns
	if len(unparsedLines) > 0 && len(unparsedLines) < len(logLines)/2 {
		logEntry.Info("Attempting to generate additional patterns for unparsed lines", map[string]interface{}{
			"unparsed_count": len(unparsedLines),
		})

		additionalPatterns, err := dps.AnalyzeLogPatterns(unparsedLines, min(50, len(unparsedLines)))
		if err == nil {
			for _, line := range unparsedLines {
				for _, pattern := range additionalPatterns {
					if entry := dps.parseLineWithPattern(line, pattern, uint(len(entries)+1)); entry != nil {
						entries = append(entries, *entry)
						break
					}
				}
			}
		}
	}

	logEntry.Info("Dynamic log parsing completed", map[string]interface{}{
		"entries_parsed": len(entries),
		"unparsed_lines": len(unparsedLines),
	})

	return entries, nil
}

// parseLineWithPattern attempts to parse a single line with a given pattern
func (dps *DynamicParserService) parseLineWithPattern(line string, pattern GeneratedPattern, lineNumber uint) *models.LogEntry {
	re, err := regexp.Compile(pattern.Regex)
	if err != nil {
		logger.Debug("Invalid regex pattern", map[string]interface{}{
			"pattern": pattern.Regex,
			"error":   err.Error(),
		})
		return nil
	}

	match := re.FindStringSubmatch(line)
	if match == nil {
		return nil
	}

	// Extract fields based on the pattern
	entry := models.LogEntry{
		LogFileID: 0,          // Will be set by caller
		Timestamp: time.Now(), // Default timestamp
		Level:     "INFO",     // Default level
		Message:   line,       // Default to full line
		Metadata:  make(map[string]interface{}),
	}

	// Map captured groups to fields
	for i, fieldName := range re.SubexpNames() {
		if i == 0 || fieldName == "" {
			continue
		}

		value := match[i]

		switch strings.ToLower(fieldName) {
		case "timestamp", "ts", "time", "date":
			if ts, err := dps.parseTimestamp(value); err == nil {
				entry.Timestamp = ts
			}
		case "level", "severity", "lvl":
			entry.Level = dps.normalizeLogLevel(value)
		case "message", "msg", "content":
			entry.Message = value
		case "hostname", "host":
			entry.Host = value
		case "process", "proc":
			entry.Service = value
		case "pid":
			entry.Metadata["pid"] = value
		default:
			entry.Metadata[fieldName] = value
		}
	}

	// Add pattern metadata
	entry.Metadata["pattern_name"] = pattern.Name
	entry.Metadata["pattern_confidence"] = pattern.Confidence
	entry.Metadata["parsing_method"] = "dynamic_llm"

	return &entry
}

// createPatternAnalysisPrompt creates a prompt for LLM to generate regex patterns
func (dps *DynamicParserService) createPatternAnalysisPrompt(request PatternAnalysisRequest) string {
	var linesText strings.Builder
	for i, line := range request.LogLines {
		linesText.WriteString(fmt.Sprintf("%d. %s\n", i+1, line))
	}

	return fmt.Sprintf(`You are an expert log parsing engineer. Analyze the following log lines and generate regex patterns to parse them.

CRITICAL INSTRUCTIONS:
- Return ONLY valid JSON in the exact format specified below
- Generate regex patterns that can extract timestamp, level, message, and other relevant fields
- Make patterns flexible enough to handle variations in the same log format
- Focus on the most common patterns first
- Ensure regex patterns are valid and will compile

LOG LINES TO ANALYZE:
%s

ANALYSIS REQUIREMENTS:
1. Identify common patterns in the log lines
2. Generate regex patterns that can extract structured data
3. Include named capture groups for each field
4. Provide confidence scores for each pattern
5. Include examples of lines that match each pattern

REQUIRED JSON FORMAT:
{
  "patterns": [
    {
      "name": "Pattern name (e.g., 'RFC3339 Systemd Format')",
      "description": "Description of what this pattern matches",
      "regex": "^(?P<timestamp>\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?(?:Z|[+-]\\d{2}:?\\d{2}))\\s+(?P<hostname>\\S+)\\s+(?P<process>\\w+)\\[(?P<pid>\\d+)\\]:\\s*(?:(?P<level>INFO|DEBUG|WARN|WARNING|ERROR|FATAL|CRITICAL)[:\\s-]*)?(?P<message>.*)$",
      "fields": ["timestamp", "hostname", "process", "pid", "level", "message"],
      "confidence": 0.95,
      "examples": ["2025-07-04T01:56:15.212666+02:00 v2202503259448321762 rclone[1514610]: INFO : vfs cache: cleaned"],
      "metadata": {
        "format_type": "systemd",
        "timestamp_format": "RFC3339"
      }
    }
  ],
  "summary": "Brief summary of the patterns found",
  "quality": "high|medium|low"
}

PATTERN GUIDELINES:
- Use named capture groups (?P<name>pattern)
- Escape special characters properly
- Make patterns robust to handle variations
- Include common timestamp formats
- Handle optional fields gracefully
- Consider multiline patterns if needed

Return ONLY the JSON object, nothing else.`, linesText.String())
}

// parsePatternAnalysisResponse parses the LLM response into structured patterns
func (dps *DynamicParserService) parsePatternAnalysisResponse(response string) ([]GeneratedPattern, error) {
	// Try to extract JSON from the response
	jsonStart := strings.Index(response, "{")
	jsonEnd := strings.LastIndex(response, "}")

	if jsonStart == -1 || jsonEnd == -1 {
		return nil, fmt.Errorf("no valid JSON found in response")
	}

	jsonStr := response[jsonStart : jsonEnd+1]

	var analysisResponse PatternAnalysisResponse
	if err := json.Unmarshal([]byte(jsonStr), &analysisResponse); err != nil {
		return nil, fmt.Errorf("failed to unmarshal pattern analysis response: %w", err)
	}

	return analysisResponse.Patterns, nil
}

// validatePatterns tests patterns against sample lines and returns valid ones
func (dps *DynamicParserService) validatePatterns(patterns []GeneratedPattern, sampleLines []string) []GeneratedPattern {
	var validPatterns []GeneratedPattern

	for _, pattern := range patterns {
		// Test if regex compiles
		re, err := regexp.Compile(pattern.Regex)
		if err != nil {
			logger.Debug("Invalid regex pattern", map[string]interface{}{
				"pattern": pattern.Regex,
				"error":   err.Error(),
			})
			continue
		}

		// Test pattern against sample lines
		matches := 0
		for _, line := range sampleLines {
			if re.MatchString(line) {
				matches++
			}
		}

		// Calculate actual confidence based on matches
		actualConfidence := float64(matches) / float64(len(sampleLines))

		// Only keep patterns with reasonable match rate
		if actualConfidence > 0.1 { // At least 10% of lines should match
			pattern.Confidence = actualConfidence
			validPatterns = append(validPatterns, pattern)

			logger.Debug("Validated pattern", map[string]interface{}{
				"pattern_name": pattern.Name,
				"matches":      matches,
				"total_lines":  len(sampleLines),
				"confidence":   actualConfidence,
			})
		}
	}

	return validPatterns
}

// getSampleLines returns a sample of log lines for analysis
func (dps *DynamicParserService) getSampleLines(logLines []string, sampleSize int) []string {
	if len(logLines) <= sampleSize {
		return logLines
	}

	// Take evenly distributed samples
	var samples []string
	step := len(logLines) / sampleSize

	for i := 0; i < sampleSize && i*step < len(logLines); i++ {
		samples = append(samples, logLines[i*step])
	}

	return samples
}

// parseTimestamp attempts to parse various timestamp formats
func (dps *DynamicParserService) parseTimestamp(timestampStr string) (time.Time, error) {
	formats := []string{
		time.RFC3339,
		time.RFC3339Nano,
		"2006-01-02T15:04:05.000Z",
		"2006-01-02T15:04:05Z",
		"2006-01-02 15:04:05",
		"2006-01-02 15:04:05.000",
		time.UnixDate,
		time.RFC822,
		time.RFC850,
	}

	for _, format := range formats {
		if t, err := time.Parse(format, timestampStr); err == nil {
			return t, nil
		}
	}

	return time.Time{}, fmt.Errorf("unable to parse timestamp: %s", timestampStr)
}

// normalizeLogLevel normalizes log levels to standard format
func (dps *DynamicParserService) normalizeLogLevel(level string) string {
	level = strings.ToUpper(strings.TrimSpace(level))

	switch level {
	case "DEBUG", "DBG":
		return "DEBUG"
	case "INFO", "INF":
		return "INFO"
	case "WARN", "WARNING":
		return "WARN"
	case "ERROR", "ERR":
		return "ERROR"
	case "FATAL", "CRITICAL", "CRIT":
		return "FATAL"
	default:
		return "INFO"
	}
}

// min returns the minimum of two integers
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}
